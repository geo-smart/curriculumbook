{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb810c40",
   "metadata": {},
   "source": [
    "# Homework 3 (10 points)\n",
    "This homework will make use of pandas dataframese to extract and manipulate metadata of seismic station in the Northern California Seismic Network. The learning objective are: data download from URL, dataframes with pandas, basic data manipulation. Use the tutorials shown in class and the pandas resources (https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119661fa",
   "metadata": {},
   "source": [
    "### Think like a researcher:\n",
    "\n",
    "We want to download seismic waveforms from a seismic data archive of specific earthquakes. We am not sure what sensors (seismometers) is operating at that time. The list of stations available in the seismic networkhas more than 6000, that's way too many! So we want to filter only the seismic stations that are relevant for the research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "286aef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Address of the website to download data\n",
    "url = 'http://ncedc.org/ftp/pub/doc/NC.info/NC.channel.summary.day'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0f53385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful Python modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import pickle\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from math import cos, sin, pi, sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c778abd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data from the website into a Python dataframe\n",
    "s = requests.get(url).content\n",
    "data = pd.read_csv(io.StringIO(s.decode('utf-8')), header=None, skiprows=2, sep='\\s+', usecols=list(range(0, 13)))\n",
    "data.columns = ['station', 'network', 'channel', 'location', 'rate', 'start_time', 'end_time', 'latitude', 'longitude', 'elevation', 'depth', 'dip', 'azimuth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4944b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform columns start_time and end_time into datetime format\n",
    "startdate = pd.to_datetime(data['start_time'], format='%Y/%m/%d,%H:%M:%S')\n",
    "data['start_time'] = startdate\n",
    "# Avoid 'OutOfBoundsDatetime' error with year 3000\n",
    "enddate = data['end_time'].str.replace('3000', '2025')\n",
    "enddate = pd.to_datetime(enddate, format='%Y/%m/%d,%H:%M:%S')\n",
    "data['end_time'] = enddate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8549ede",
   "metadata": {},
   "source": [
    "After discussing with my adviser, we decided than only the following channels are relevant for the work we want to do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd879dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = ['BHE', 'BHN', 'BHZ', 'BH1', 'BH2', \\\n",
    "            'EHE', 'EHN', 'EHZ', 'EH1', 'EH2', \\\n",
    "            'HHE', 'HHN', 'HHZ', 'HH1', 'HH2', \\\n",
    "            'SHE', 'SHN', 'SHZ', 'SH1', 'SH2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e95bd0",
   "metadata": {},
   "source": [
    "## Q1 (2 points)\n",
    "\n",
    "Filter the dataset to keep only the rows with the channels as defined above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecc9729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7c5bcce",
   "metadata": {},
   "source": [
    "## Q2  (2 points)\n",
    "My earthquake catalog starts on 2007/07/01 and ends on 2009/07/01. I am only interested in stations that started recording before 2007/07/01 and ended recording after 2009/07/01. The dataframe <code>data</code> has the start time and end times defined as <code>datetime</code> objects. That means that we can filter the dataframe columns by comparing the datetime objects. To create a datetime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c2f5648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datetime.datetime'>\n"
     ]
    }
   ],
   "source": [
    "s1 = datetime(2007,7,1)\n",
    "s2 = datetime(2009,7,1)\n",
    "print(type(s1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30615610",
   "metadata": {},
   "source": [
    "Filter the dataset to keep only stations that started recording before 2007/07/01 and ended recording after 2009/07/01. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63823607",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0436861",
   "metadata": {},
   "source": [
    "The cluster of these repeating earthquakes are located at latitude = 40.09N and longitude = -122.87E. Here is a function to compute the distance from the station to the earthquakes, and to add a column distance to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8815da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the cluster of earthquakes is centered at the following location:\n",
    "lat0 = 40.09000\n",
    "lon0 = -122.87000\n",
    "\n",
    "a = 6378.136 # radius of the Earth in km.\n",
    "e = 0.006694470 # ellipticity\n",
    "\n",
    "\n",
    "dx = (pi / 180.0) * a * cos(lat0 * pi / 180.0) / sqrt(1.0 - e * e * sin(lat0 * pi / 180.0) * sin(lat0 * pi / 180.0))\n",
    "dy = (3.6 * pi / 648.0) * a * (1.0 - e * e) / ((1.0 - e * e * sin(lat0 * pi / 180.0) * sin(lat0 * pi / 180.0)) ** 1.5)\n",
    "x = dx * (data['longitude'] - lon0)\n",
    "y = dy * (data['latitude'] - lat0)\n",
    "\n",
    "# calculate and fill in the dataframe with the new values\n",
    "data['distance'] = np.sqrt(np.power(x, 2.0) + np.power(y, 2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1794fc6a",
   "metadata": {},
   "source": [
    "## Q3  (3 points)\n",
    "We want to keep the stations that are located less than 100 km from my repeating earthquakes. For stations farther away, the signal-to-noise ratio would be too low. Filter the dataset to keep only stations that are within 100 km from the earthquakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8ccfee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "733269f3",
   "metadata": {},
   "source": [
    "Finally, we want to group the result such that the final result looks organized like this:\n",
    "\n",
    "|station|network|location|latitude|longitude |elevation|depth|distance |channel    |start_time         |end_time           |\n",
    "|-------|-------|--------|--------|----------|---------|-----|---------|-----------|-------------------|-------------------|\n",
    "|KBS \t|NC \t|-- \t |39.91719|-123.59561|1120.0   |0.0  |64.720762|SHZ        |2002-10-17 00:00:00|2011-10-27 21:25:00|\n",
    "|KCPB \t|NC \t|-- \t |39.68631|-123.58242|1261.0   |0.0  |75.502041|HHZ,HHN,HHE|2006-10-18 00:08:00|2010-11-01 22:00:00|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8e4378",
   "metadata": {},
   "source": [
    "We want one row per station, a against one row per channel. Use the pandas function <code>agg</code> to group the channels of a given station together, and srt with the earliest start date and the latest end date. Do not forget to reset the indices!\n",
    "You can use the following function to group the channels together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cffd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    \"\"\"\n",
    "    Concatenate channels\n",
    "    \"\"\"\n",
    "    result = '%s' % ','.join(x)\n",
    "    result = list(set(result.split(',')))\n",
    "    result = '%s' % ','.join(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b99603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "138d00ad",
   "metadata": {},
   "source": [
    "## Q4  (3 points)\n",
    "\n",
    "How many stations are left in the dataset? Can you plot them using a mapping toolbox or matplotlib? Please add  axis labels, update the fontsize to 14 points, add a title, and a legend, save the file as a PNG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db24acca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
